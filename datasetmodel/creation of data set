{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjaligurram/datasetandmodel/blob/main/Creation_of_data_set_and_save_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTNn1emGf4HR",
        "outputId": "f026b1eb-9386-443a-93f0-ad02e289bd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV5qITuMgQkc",
        "outputId": "5e18a001-37be-4bd5-98a3-82fcda234dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 316 frames and saved to 'frames_dataset' folder.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Create a folder to store frames\n",
        "output_folder = \"frames_dataset\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"/content/ibmvideo.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image\n",
        "    frame_filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "    cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # Break the loop after a certain number of frames (if needed)\n",
        "    # if frame_count == 100:\n",
        "    #     break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Converted {frame_count} frames and saved to '{output_folder}' folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dpTSosv-gQuJ",
        "outputId": "f52af248-72a9-4304-85a5-515c459f8133"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f211810f-3d35-4cdb-906c-20fcf8e0e6a7\", \"frames_dataset.zip\", 16656513)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"/content/frames_dataset\", 'zip', \"frames_dataset\")\n",
        "files.download(\"/content/frames_dataset.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TOcDcPOhjqV",
        "outputId": "57da8fb0-d052-48cf-d02b-2422f97bb96a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames organized into class-specific subdirectories.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create a directory for the organized frames\n",
        "output_directory = \"frames_dataset\"\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# List all the frames in the current directory\n",
        "frame_files = [filename for filename in os.listdir() if filename.endswith('.jpg')]\n",
        "\n",
        "# Create class subdirectories and move frames to appropriate subdirectories\n",
        "for filename in frame_files:\n",
        "    # Determine class based on filename, e.g., classA_frame_0001.jpg\n",
        "    class_name = filename.split('_')[0]\n",
        "\n",
        "    # Create class subdirectory if it doesn't exist\n",
        "    class_dir = os.path.join(output_directory, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    # Move the frame to the class subdirectory\n",
        "    shutil.move(filename, os.path.join(class_dir, filename))\n",
        "\n",
        "print(\"Frames organized into class-specific subdirectories.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj93P_-yjGcq",
        "outputId": "c06b37b2-2e10-4340-f62a-98fa479fc1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upaFnIVWjcpP",
        "outputId": "17de6399-303e-42c0-ade1-65da128459fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames organized into class-specific subdirectories within frames_dataset.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the list of classes\n",
        "classes = [\"classA\", \"classB\"]\n",
        "\n",
        "# Create the frames_dataset directory if it doesn't exist\n",
        "output_directory = \"frames_dataset\"\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Loop through each class and create a subdirectory\n",
        "for class_name in classes:\n",
        "    class_directory = os.path.join(output_directory, class_name)\n",
        "    os.makedirs(class_directory, exist_ok=True)\n",
        "\n",
        "# List all the frames in the current directory\n",
        "frame_files = [filename for filename in os.listdir() if filename.endswith('.jpg')]\n",
        "\n",
        "# Organize frames into class subdirectories\n",
        "for filename in frame_files:\n",
        "    # Determine class based on filename, e.g., classA_frame_0001.jpg\n",
        "    class_name = filename.split('_')[0]\n",
        "    if class_name in classes:\n",
        "        target_directory = os.path.join(output_directory, class_name)\n",
        "        shutil.move(filename, os.path.join(target_directory, filename))\n",
        "\n",
        "print(\"Frames organized into class-specific subdirectories within frames_dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCnScbaijqlQ",
        "outputId": "fed7d84f-b4c3-4daa-aeaa-c9a359f7d3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Class Indices: {'classA': 0, 'classB': 1}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define constants\n",
        "image_height = 224  # Set the desired height\n",
        "image_width = 224   # Set the desired width\n",
        "batch_size = 32\n",
        "\n",
        "# Create an ImageDataGenerator for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,  # Normalize pixel values\n",
        "    # You can add more augmentation options here\n",
        ")\n",
        "\n",
        "# Load training data using the generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"frames_dataset\",  # Path to the directory with organized frames\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\"  # Use \"categorical\" for multi-class classification\n",
        ")\n",
        "\n",
        "# Example: Printing the class indices\n",
        "print(\"Class Indices:\", train_generator.class_indices)\n",
        "\n",
        "# Now you can use train_generator to train your machine learning model\n",
        "# For example:\n",
        "# model.fit(train_generator, ...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lHoKGVfUkF36"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b6Nl2v1Wk3bC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define constants\n",
        "num_frames_per_clip = 16\n",
        "image_height = 112\n",
        "image_width = 112\n",
        "\n",
        "def load_and_preprocess_clip(clip_path):\n",
        "    clip_frames = []\n",
        "    for frame_name in sorted(os.listdir(clip_path)):\n",
        "        if frame_name.endswith('.jpg'):\n",
        "            frame_path = os.path.join(clip_path, frame_name)\n",
        "            frame = cv2.imread(frame_path)\n",
        "            frame = cv2.resize(frame, (image_width, image_height))\n",
        "            clip_frames.append(frame)\n",
        "            if len(clip_frames) == num_frames_per_clip:\n",
        "                break\n",
        "    return np.array(clip_frames)\n",
        "\n",
        "# Load video clips and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "class_names = sorted(os.listdir(\"frames_dataset\"))\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(\"frames_dataset\", class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        class_label = class_names.index(class_name)  # Assign class label based on class_names list\n",
        "        for clip_name in os.listdir(class_dir):\n",
        "            clip_path = os.path.join(class_dir, clip_name)\n",
        "            clip_frames = load_and_preprocess_clip(clip_path)\n",
        "            data.append(clip_frames)\n",
        "            labels.append(class_label)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "num_classes = len(class_names)\n",
        "labels_categorical = to_categorical(labels, num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7oDsixD_lFeG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames_per_clip, image_height, image_width, 3)),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TSIwZUean3tc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to categorical format\n",
        "num_classes = 2\n",
        "labels_categorical = to_categorical(labels, num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "scMWxUT7pQJ0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames_per_clip, image_height, image_width, 3)),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdYDdnh0oi7i",
        "outputId": "b5038c85-4c7a-4bb2-e948-de1709501742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uG_ncvLYqIeb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Define constants\n",
        "num_frames_per_clip = 16  # Number of frames per video clip\n",
        "image_height = 112        # Set your desired image dimensions\n",
        "image_width = 112\n",
        "\n",
        "def load_and_preprocess_clip(clip_path):\n",
        "    clip_frames = []\n",
        "    for frame_name in sorted(os.listdir(clip_path)):\n",
        "        if frame_name.endswith('.jpg'):\n",
        "            frame_path = os.path.join(clip_path, frame_name)\n",
        "            frame = cv2.imread(frame_path)\n",
        "            frame = cv2.resize(frame, (image_width, image_height))\n",
        "            clip_frames.append(frame)\n",
        "            if len(clip_frames) == num_frames_per_clip:\n",
        "                break\n",
        "    return np.array(clip_frames)\n",
        "\n",
        "# Load frames from classB directory\n",
        "classB_frames = []\n",
        "classB_dir = os.path.join(\"frames_dataset\", \"classB\")\n",
        "\n",
        "for clip_name in os.listdir(classB_dir):\n",
        "    clip_path = os.path.join(classB_dir, clip_name)\n",
        "    clip_frames = load_and_preprocess_clip(clip_path)\n",
        "    classB_frames.append(clip_frames)\n",
        "\n",
        "classB_data = np.array(classB_frames)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ChAwwL9SqLFF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "\n",
        "num_classes = 2  # Two classes: classA and classB\n",
        "\n",
        "model = Sequential([\n",
        "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames_per_clip, image_height, image_width, 3)),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N8j3CAnKq00t",
        "outputId": "49e73739-43c1-4a41-96aa-112d560dd598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m912.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 2.2.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.6.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_LkDyaDArQy0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "azWq7P_FrT5J"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UAA_DXskrXmU"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames_per_clip, image_height, image_width, 3)),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Flatten(),  # Flatten the output before the Dense layers\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MAk9Am-7rgwi"
      },
      "outputs": [],
      "source": [
        "# Convert labels to categorical format\n",
        "classB_labels = np.zeros(len(classB_frames))  # Label 0 for classB\n",
        "classB_labels_categorical = to_categorical(classB_labels, num_classes=num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eOlwMc5irxbz"
      },
      "outputs": [],
      "source": [
        "# Create and compile the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = 2  # Two classes: classA and classB\n",
        "\n",
        "model = Sequential([\n",
        "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames_per_clip, image_height, image_width, 3)),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#train and test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Example data dimensions and parameters\n",
        "num_samples = 1000\n",
        "num_frames_per_clip = 16\n",
        "image_height = 64\n",
        "image_width = 64\n",
        "num_classes = 2\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Generate example data\n",
        "X_train = np.random.rand(num_samples, num_frames_per_clip, image_height, image_width, 3)\n",
        "y_train = np.random.randint(num_classes, size=num_samples)\n",
        "X_val = np.random.rand(num_samples // 5, num_frames_per_clip, image_height, image_width, 3)\n",
        "y_val = np.random.randint(num_classes, size=num_samples // 5)\n",
        "X_test = np.random.rand(num_samples // 5, num_frames_per_clip, image_height, image_width, 3)\n",
        "y_test = np.random.randint(num_classes, size=num_samples // 5)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val = to_categorical(y_val, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define and compile your model\n",
        "model = Sequential([\n",
        "    Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames_per_clip, image_height, image_width, 3)),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(2, 2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=num_epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w_oiBGyqL_N",
        "outputId": "f059d481-cf80-40dd-9e48-0c46e328d111"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 481s 14s/step - loss: 1.2504 - accuracy: 0.4980 - val_loss: 0.6930 - val_accuracy: 0.5100\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 455s 14s/step - loss: 0.6936 - accuracy: 0.4830 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 455s 14s/step - loss: 0.6933 - accuracy: 0.4940 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 462s 14s/step - loss: 0.6934 - accuracy: 0.4950 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 456s 14s/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5100\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 449s 14s/step - loss: 0.6931 - accuracy: 0.5110 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 454s 14s/step - loss: 0.6930 - accuracy: 0.5040 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 445s 14s/step - loss: 0.6931 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.4900\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 446s 14s/step - loss: 0.6933 - accuracy: 0.5100 - val_loss: 0.6935 - val_accuracy: 0.4900\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 446s 14s/step - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.4900\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 448s 14s/step - loss: 0.6930 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.4900\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 448s 14s/step - loss: 0.6930 - accuracy: 0.5090 - val_loss: 0.6938 - val_accuracy: 0.4900\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 451s 14s/step - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6939 - val_accuracy: 0.4900\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 451s 14s/step - loss: 0.6930 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.4900\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 444s 14s/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6939 - val_accuracy: 0.4900\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 449s 14s/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.4900\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 442s 14s/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.4900\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 436s 14s/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.4900\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 452s 14s/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.4900\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 436s 14s/step - loss: 0.6934 - accuracy: 0.5070 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6936 - accuracy: 0.4800\n",
            "Test loss: 0.6936, Test accuracy: 0.4800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model\n",
        "model.save(\"silent_speech_model.h5\")"
      ],
      "metadata": {
        "id": "Z0Wrc6A4OE4t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm5nhTyftQZI"
      },
      "source": [
        "Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PXg5jnGtOSO",
        "outputId": "6a1dec29-fcfc-4f99-cb17-2ebb40c84e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1B2aBSf1tYk6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Specify the path to the classB frames\n",
        "classB_dir = os.path.join(\"frames_dataset\", \"classB\")\n",
        "\n",
        "# Load and visualize frames from classB\n",
        "for clip_name in os.listdir(classB_dir):\n",
        "    clip_path = os.path.join(classB_dir, clip_name)\n",
        "    frame_paths = [os.path.join(clip_path, frame_name) for frame_name in sorted(os.listdir(clip_path)) if frame_name.endswith('.jpg')]\n",
        "\n",
        "    for frame_path in frame_paths:\n",
        "        frame = cv2.imread(frame_path)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "        plt.imshow(frame)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Lzs3pOL6thFe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time  # Import the time module\n",
        "\n",
        "# Specify the path to the classB frames\n",
        "classB_dir = os.path.join(\"frames_dataset\", \"classB\")\n",
        "\n",
        "# Load and visualize frames from classB\n",
        "for clip_name in os.listdir(classB_dir):\n",
        "    clip_path = os.path.join(classB_dir, clip_name)\n",
        "    frame_paths = [os.path.join(clip_path, frame_name) for frame_name in sorted(os.listdir(clip_path)) if frame_name.endswith('.jpg')]\n",
        "\n",
        "    for frame_path in frame_paths:\n",
        "        print(\"Loading frame:\", frame_path)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(frame)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        time.sleep(100000)  # Add a delay of 1 second between frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-KobnQZGupjb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "classB_dir = os.path.join(\"frames_dataset\", \"classB\")\n",
        "\n",
        "for clip_name in os.listdir(classB_dir):\n",
        "    clip_path = os.path.join(classB_dir, clip_name)\n",
        "    frame_paths = [os.path.join(clip_path, frame_name) for frame_name in sorted(os.listdir(clip_path)) if frame_name.endswith('.jpg')]\n",
        "\n",
        "    for frame_path in frame_paths:\n",
        "        print(\"Loading frame:\", frame_path)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "        cv2.waitKey(1000)  # Display for 1 second (1000 milliseconds)\n",
        "        cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5scv3lCcxp4r",
        "outputId": "a97faa24-3bbd-49fa-ce4e-7786f9e94ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as frames_dataset.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Define constants\n",
        "image_height = 112\n",
        "image_width = 112\n",
        "\n",
        "# Specify paths to your frames and labels\n",
        "frames_folder = \"frames_dataset\"\n",
        "class_names = os.listdir(frames_folder)\n",
        "\n",
        "# Initialize arrays to store data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Load and preprocess frames\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(frames_folder, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        class_label = class_name  # Use the class name directly as the label\n",
        "        for clip_name in os.listdir(class_dir):\n",
        "            clip_path = os.path.join(class_dir, clip_name)\n",
        "            frame_paths = [os.path.join(clip_path, frame_name) for frame_name in sorted(os.listdir(clip_path)) if frame_name.endswith('.jpg')]\n",
        "            clip_frames = []\n",
        "            for frame_path in frame_paths:\n",
        "                frame = cv2.imread(frame_path)\n",
        "                frame = cv2.resize(frame, (image_width, image_height))\n",
        "                clip_frames.append(frame)\n",
        "            data.append(clip_frames)\n",
        "            labels.append(class_label)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Save the dataset\n",
        "dataset_filename = \"frames_dataset.pkl\"\n",
        "with open(dataset_filename, 'wb') as file:\n",
        "    pickle.dump((data, labels), file)\n",
        "\n",
        "print(\"Dataset saved as\", dataset_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksD20fdW50L7",
        "outputId": "c935f4bb-b47c-4999-bf2a-b32f8795442a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (0,)\n",
            "Labels shape: (0,)\n",
            "No data found in the dataset.\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "dataset_filename = \"/content/frames_dataset.pkl\"\n",
        "with open(dataset_filename, 'rb') as file:\n",
        "    data, labels = pickle.load(file)\n",
        "\n",
        "# Print the shape of data and labels\n",
        "print(\"Data shape:\", data.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "# Check if data is empty or contains actual clips\n",
        "if data.shape[0] == 0:\n",
        "    print(\"No data found in the dataset.\")\n",
        "else:\n",
        "    # Assuming data contains frames organized as clips and each clip has multiple frames\n",
        "    # You can visualize a random clip of frames\n",
        "    random_clip_index = np.random.randint(0, data.shape[0])\n",
        "    random_clip_frames = data[random_clip_index]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i, frame in enumerate(random_clip_frames):\n",
        "        plt.subplot(1, len(random_clip_frames), i + 1)\n",
        "        plt.imshow(frame)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Class label:\", labels[random_clip_index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVVPjRV4BHqv",
        "outputId": "adcddaa3-3e3f-4741-c00d-25340f8fd28d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New pickle dataset saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load frames and organize data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "class_names = os.listdir(\"frames_dataset\")\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(\"frames_dataset\", class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for clip_name in os.listdir(class_dir):\n",
        "            clip_path = os.path.join(class_dir, clip_name)\n",
        "            frame_paths = [os.path.join(clip_path, frame_name) for frame_name in sorted(os.listdir(clip_path)) if frame_name.endswith('.jpg')]\n",
        "            clip_frames = []\n",
        "            for frame_path in frame_paths:\n",
        "                frame = cv2.imread(frame_path)\n",
        "                frame = cv2.resize(frame, (112, 112))\n",
        "                clip_frames.append(frame)\n",
        "            data.append(clip_frames)\n",
        "            labels.append(class_name)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Save the dataset as a pickle file\n",
        "with open(\"new_frames_dataset.pkl\", 'wb') as file:\n",
        "    pickle.dump((data, labels), file)\n",
        "\n",
        "print(\"New pickle dataset saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg1RKkYfBl6B",
        "outputId": "3d449155-06a5-45e3-a3f7-b670b1afad84"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No data found in the dataset.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the new pickle dataset\n",
        "new_dataset_filename = \"new_frames_dataset.pkl\"\n",
        "with open(new_dataset_filename, 'rb') as file:\n",
        "    data, labels = pickle.load(file)\n",
        "\n",
        "# Check if data is empty or has valid shape\n",
        "if data.shape[0] == 0:\n",
        "    print(\"No data found in the dataset.\")\n",
        "else:\n",
        "    # Assuming data contains frames organized as clips and each clip has multiple frames\n",
        "    # Let's visualize a random clip of frames\n",
        "    random_clip_index = np.random.randint(0, data.shape[0])\n",
        "    random_clip_frames = data[random_clip_index]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i, frame in enumerate(random_clip_frames):\n",
        "        plt.subplot(1, len(random_clip_frames), i + 1)\n",
        "        plt.imshow(frame)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Class label:\", labels[random_clip_index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFQihRAZGDD4",
        "outputId": "696b3697-5bc8-4e26-a853-6ca347dfdff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `pip install tensorflow==<desired_version>'\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow==<desired_version>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBuG1tRKErZP",
        "outputId": "59d6dddb-4591-49b8-8d49-a9ccfd8e585e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkhpYt2BG-a0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_and_preprocess_frames(frames_folder):\n",
        "    frames = []\n",
        "    for frame_name in sorted(os.listdir(frames_folder)):\n",
        "        if frame_name.endswith('.jpg'):\n",
        "            frame_path = os.path.join(frames_folder, frame_name)\n",
        "            frame = cv2.imread(frame_path)\n",
        "            frame = cv2.resize(frame, (224, 224))  # Resize frames to a common size\n",
        "            frame = frame / 255.0  # Normalize pixel values to [0, 1]\n",
        "            frames.append(frame)\n",
        "    return np.array(frames)\n",
        "\n",
        "frames_folder = \"frames_dataset/classB\"\n",
        "frames_data = load_and_preprocess_frames(frames_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Uaj7-RQIDH2"
      },
      "outputs": [],
      "source": [
        "pip install keras_applications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60FmI8qjIadr",
        "outputId": "f769bed1-230e-49ec-c930-c036656dcc22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bExbJfvwJaX1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming frames_data contains your preprocessed frames\n",
        "\n",
        "num_frames = len(frames_data)\n",
        "\n",
        "for i in range(num_frames):\n",
        "    plt.imshow(frames_data[i])\n",
        "    plt.title(f\"Frame {i}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIHBmuIxrx6Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Assuming 'frames_dataset' is a list of file paths to frames\n",
        "frames_dataset = [\"/content/frames_dataset/frame_0000.jpg\",\"/content/frames_dataset/frame_0001.jpg\"]\n",
        "\n",
        "# Load frames and convert to suitable format\n",
        "frame_images = [img_to_array(load_img(frame_path)) for frame_path in frames_dataset]\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "frame_data = np.array(frame_images)\n",
        "\n",
        "# Create a TensorFlow Dataset\n",
        "frame_dataset = tf.data.Dataset.from_tensor_slices(frame_data)\n",
        "\n",
        "# Now you can use 'frame_dataset' with TensorFlow for training or other purposes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6SCa2pE4dvu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have already created 'frame_dataset' using the previous code\n",
        "\n",
        "# Choose the number of frames you want to view\n",
        "num_frames_to_view = 1\n",
        "\n",
        "for _ in range(num_frames_to_view):\n",
        "    # Recreate the iterator to start from the beginning each time\n",
        "    iterator = frame_dataset.__iter__()\n",
        "\n",
        "    frame = iterator.get_next()  # Get the next frame\n",
        "    plt.imshow(frame.numpy().astype(\"uint8\"))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ow8jS7L5AWL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming we have already created 'frame_dataset' using the previous code\n",
        "\n",
        "# Convert the dataset to a list of flattened frame a/coays\n",
        "frame_list = [frame.numpy().flatten() for frame in frame_dataset]\n",
        "\n",
        "# Create a Pandas DataFrame from the list\n",
        "df = pd.DataFrame(frame_list)\n",
        "\n",
        "# Display the DataFrame as a table\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPGSh0omfkIN"
      },
      "outputs": [],
      "source": [
        "# lip_reading_model.py\n",
        "def predict(frames):\n",
        "    # Implement your lip-reading model's prediction logic here\n",
        "    # Return the recognized text\n",
        "    return \"Recognized Text Placeholder\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model(\"/content/silent_speech_model.h5\")\n",
        "\n",
        "# Example input data for prediction\n",
        "num_samples = 10\n",
        "num_frames_per_clip = 16\n",
        "image_height = 64\n",
        "image_width = 64\n",
        "\n",
        "input_data = np.random.rand(num_samples, num_frames_per_clip, image_height, image_width, 3)\n",
        "\n",
        "# Perform prediction using the loaded model\n",
        "predictions = loaded_model.predict(input_data)\n",
        "\n",
        "# Process the predictions as needed\n",
        "# For example, convert probabilities to labels or phrases\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRcleY13TfPA",
        "outputId": "5c62e3b3-4ca7-4435-d201-c73eac833f25"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 609ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xGpeIEaNto1NUIF4wRXY7bzM8G8jBK46",
      "authorship_tag": "ABX9TyP+vPVgGPWBYofdKnr++mqe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
